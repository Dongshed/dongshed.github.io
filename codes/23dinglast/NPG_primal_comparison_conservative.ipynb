{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPG primal comparison for finite constrained MDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSet-up:\\n1) Softmax policy \\n2) Bounded rewards\\n3) Many states and actions\\n4) Regularized (Natural) policy gradient + primal-dual method\\n   (Natural) policy gradient + optimistic primal-dual method\\n   (Natural) policy gradient + primal method\\n\\nReferences:\\n1) NPG primal   \\n   CRPO: A New Approach for Safe Reinforcement Learning with Convergence Guarantee\\n   http://proceedings.mlr.press/v139/xu21a/xu21a.pdf\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Set-up:\n",
    "1) Softmax policy \n",
    "2) Bounded rewards\n",
    "3) Many states and actions\n",
    "4) Regularized (Natural) policy gradient + primal-dual method\n",
    "   (Natural) policy gradient + optimistic primal-dual method\n",
    "   (Natural) policy gradient + primal method\n",
    "\n",
    "References:\n",
    "1) NPG primal   \n",
    "   CRPO: A New Approach for Safe Reinforcement Learning with Convergence Guarantee\n",
    "   http://proceedings.mlr.press/v139/xu21a/xu21a.pdf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.6f}\".format(x)})\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Seed\n",
    "np.random.seed(10) \n",
    "## Problem Setup\n",
    "gamma = 0.9\n",
    "n, m = 20, 5 # s, a\n",
    "'''\n",
    "Randomly generated probability transition matrix P((s,a) -> s') in R^{|S||A| x |S|}\n",
    "Each row sums up to one\n",
    "'''\n",
    "raw_transition = np.random.uniform(0,1,size=(n*m,n))\n",
    "prob_transition = raw_transition/raw_transition.sum(axis=1,keepdims=1)\n",
    "'''\n",
    "Random positive rewards\n",
    "'''\n",
    "reward = np.random.uniform(0,1,size=(n*m))\n",
    "\n",
    "'''\n",
    "Random utilities between -1 and +1\n",
    "'''\n",
    "utility = np.random.uniform(-1,1,size=(n*m))\n",
    "\n",
    "'''\n",
    "Start state distribution\n",
    "'''\n",
    "rho = np.ones(n)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: theta as an array and \n",
    "Ouput: array of probabilites corresponding to each state: [\\pi_{s_1}(.), ...., \\pi_{s_n}(.)]\n",
    "'''\n",
    "def theta_to_policy(theta,n,m):\n",
    "    prob = []\n",
    "    for i in range(n):\n",
    "        norm = np.sum(np.exp(theta[m*i:m*(i+1)]))\n",
    "        for j in range(m*i,m*(i+1)):\n",
    "            prob.append(np.exp(theta[j])/norm)\n",
    "            \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: theta as an array and \n",
    "Ouput: array of probabilites corresponding to each state: [\\pi_{s_1}(.), ...., \\pi_{s_n}(.)]\n",
    "'''\n",
    "def revise_array_up(arr, x):\n",
    "    revised_arr = [num if num <= x else x for num in arr]\n",
    "    return revised_arr\n",
    "\n",
    "def revise_array_low(arr, x):\n",
    "    revised_arr = [num if num >= x else x for num in arr]\n",
    "    return revised_arr\n",
    "\n",
    "def theta_to_policy_cutoff(theta,n,m):\n",
    "    \n",
    "    # revise theta to be in some interval [-C, C]\n",
    "    C = 10000\n",
    "    revised_theta = revise_array_up(theta, C)\n",
    "    revised_theta = revise_array_low(revised_theta, -C)\n",
    "    \n",
    "#     print('Theta',theta)\n",
    "    \n",
    "#     print('Revised Theta',revised_theta)\n",
    "    \n",
    "    prob = []\n",
    "    for i in range(n):\n",
    "        norm = np.sum(np.exp(revised_theta[m*i:m*(i+1)]))\n",
    "        for j in range(m*i,m*(i+1)):\n",
    "            prob.append(np.exp(revised_theta[j])/norm)\n",
    "            \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: theta as an array and \n",
    "Ouput: array of probabilites corresponding to each state: [\\pi_{s_1}(.), ...., \\pi_{s_n}(.)]\n",
    "'''\n",
    "def theta_to_policy_naive(theta,n,m):\n",
    "    prob = []\n",
    "    for i in range(n):\n",
    "        norm = np.sum(theta[m*i:m*(i+1)])\n",
    "        for j in range(m*i,m*(i+1)):\n",
    "            prob.append(theta[j]/norm)\n",
    "            \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "License: BSD\n",
    "Author: Mathieu Blondel\n",
    "Implements three algorithms for projecting a vector onto the simplex: sort, pivot and bisection.\n",
    "For details and references, see the following paper:\n",
    "Large-scale Multiclass Support Vector Machine Training via Euclidean Projection onto the Simplex\n",
    "Mathieu Blondel, Akinori Fujino, and Naonori Ueda.\n",
    "ICPR 2014.\n",
    "http://www.mblondel.org/publications/mblondel-icpr2014.pdf\n",
    "\"\"\"\n",
    "\n",
    "def projection_simplex_sort(v, z=1):\n",
    "    n_features = v.shape[0]\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u) - z\n",
    "    ind = np.arange(n_features) + 1\n",
    "    cond = u - cssv / ind > 0\n",
    "    rho = ind[cond][-1]\n",
    "    theta = cssv[cond][-1] / float(rho)\n",
    "    w = np.maximum(v - theta, 0)\n",
    "    return w\n",
    "\n",
    "\n",
    "def projection_simplex_pivot(v, z=1, random_state=None):\n",
    "    rs = np.random.RandomState(random_state)\n",
    "    n_features = len(v)\n",
    "    U = np.arange(n_features)\n",
    "    s = 0\n",
    "    rho = 0\n",
    "    while len(U) > 0:\n",
    "        G = []\n",
    "        L = []\n",
    "        k = U[rs.randint(0, len(U))]\n",
    "        ds = v[k]\n",
    "        for j in U:\n",
    "            if v[j] >= v[k]:\n",
    "                if j != k:\n",
    "                    ds += v[j]\n",
    "                    G.append(j)\n",
    "            elif v[j] < v[k]:\n",
    "                L.append(j)\n",
    "        drho = len(G) + 1\n",
    "        if s + ds - (rho + drho) * v[k] < z:\n",
    "            s += ds\n",
    "            rho += drho\n",
    "            U = L\n",
    "        else:\n",
    "            U = G\n",
    "    theta = (s - z) / float(rho)\n",
    "    return np.maximum(v - theta, 0)\n",
    "\n",
    "\n",
    "def projection_simplex_bisection(v, z=1, tau=0.0001, max_iter=1000):\n",
    "    func = lambda x: np.sum(np.maximum(v - x, 0)) - z\n",
    "    lower = np.min(v) - z / len(v)\n",
    "    upper = np.max(v)\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        midpoint = (upper + lower) / 2.0\n",
    "        value = func(midpoint)\n",
    "\n",
    "        if abs(value) <= tau:\n",
    "            break\n",
    "\n",
    "        if value <= 0:\n",
    "            upper = midpoint\n",
    "        else:\n",
    "            lower = midpoint\n",
    "\n",
    "    return np.maximum(v - midpoint, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: theta as an array and \n",
    "Ouput: array of probabilites corresponding to each state: [\\pi_{s_1}(.), ...., \\pi_{s_n}(.)]\n",
    "'''\n",
    "def project_to_policy(theta,n,m):\n",
    "    prob = []\n",
    "    prob_pers = []\n",
    "    for i in range(n):\n",
    "#         norm = np.sum(np.exp(theta[m*i:m*(i+1)]))\n",
    "        prob_pers = projection_simplex_sort(theta[m*i:m*(i+1)], z=1)\n",
    "        for j in range(m):\n",
    "            prob.append(prob_pers[j])\n",
    "            \n",
    "    return np.asarray(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get \\Pi_{\\pi}((s) -> (s,a)) in R^{|S| x |S||A|} matrix corresponding to the policy \\pi using the prob vector\n",
    "'''\n",
    "def get_Pi(prob,n,m):\n",
    "    Pi = np.zeros((n,n*m))\n",
    "    for i in range(n):\n",
    "        Pi[i,i*m:(i+1)*m] = prob[i*m:(i+1)*m]\n",
    "    \n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: probability vector, state, action\n",
    "Output: \\nabla_{\\theta} \\pi_{\\theta}(s,a)\n",
    "\n",
    "States go from 0 to n-1 and actons from 0 to m-1\n",
    "'''\n",
    "def grad_state_action(prob,state,action):\n",
    "    grad = np.zeros(n*m)\n",
    "    for j in range(0,m):\n",
    "        if j == action:\n",
    "            grad[m*state + j] = prob[m*state + j]*(1-prob[m*state + j])\n",
    "        else:\n",
    "            grad[m*state + j] = -prob[m*state + action]*prob[m*state + j]\n",
    "            \n",
    "    return grad\n",
    "\n",
    "def grad_state(qvals,prob,state):\n",
    "    grad = np.sum([qvals[state*m + i]*grad_state_action(prob,state,i) for i in range(0,m)],axis=0)\n",
    "    return grad\n",
    "\n",
    "def grad(qvals,prob,d_pi):\n",
    "    grad = np.sum([d_pi[i]*grad_state(qvals,prob,i) for i in range(0,n)],axis=0)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: probability vector\n",
    "Output: Fisher information matrix\n",
    "        \\nabla_{\\theta} \\pi_{\\theta}(s,a) x {\\nabla_{\\theta} \\pi_{\\theta}(s,a)}^T\n",
    "'''\n",
    "def Fisher_info(prob,d_pi):\n",
    "    qvals_one = np.ones(n*m)\n",
    "    grad = np.sum([d_pi[i]*grad_state(qvals_one,prob,i) for i in range(0,n)],axis=0)\n",
    "    fisher = np.outer(grad,grad)+1e-3*np.identity(n*m)\n",
    "    return fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The overall reward function \\ell(\\theta)\n",
    "'''\n",
    "def ell(qvals,prob,rho):\n",
    "    V = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        V[i] = np.sum([qvals[i*m + j]*prob[i*m + j] for j in range(m)])\n",
    "    \n",
    "    ell = np.dot(V,rho)\n",
    "    return ell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The overall reward advantage function \\ell(\\theta)\n",
    "'''\n",
    "def avals(qvals,prob):\n",
    "    V = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        V[i] = np.sum([qvals[i*m + j]*prob[i*m + j] for j in range(m)])\n",
    "    \n",
    "    A = qvals\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            A[i*m + j] = qvals[i*m + j] - V[i]\n",
    "        \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The projection function\n",
    "Input: a scalar \n",
    "Output: a scalar in the interval [0 C]\n",
    "'''\n",
    "def proj(scalar,gamma):\n",
    "    offset = 1000/(1-gamma)\n",
    "    if scalar < 0:\n",
    "        scalar = 0\n",
    "\n",
    "    if scalar > offset:\n",
    "        scalar = offset\n",
    "\n",
    "    return scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Iteration to check feasibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vec = np.random.uniform(0,1,size=(n,m))\n",
    "prob_vec = raw_vec/raw_vec.sum(axis=1,keepdims=1)\n",
    "init_policy = prob_vec.flatten()## Policy Iteration to get the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Policy iteration function\n",
    "'''\n",
    "def policy_iter(q_vals,n,m):\n",
    "    new_policy = np.zeros(n*m)\n",
    "    for i in range(n):\n",
    "        idx = np.argmax(q_vals[i*m:(i+1)*m])\n",
    "        new_policy[i*m + idx] = 1\n",
    "    \n",
    "    return new_policy       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting policy [0.022861 0.022257 0.496791 0.417151 0.040940 0.260055 0.020741 0.239421\n",
      " 0.113255 0.366528 0.077009 0.252897 0.293405 0.147306 0.229383 0.234235\n",
      " 0.114754 0.214643 0.266094 0.170273 0.019934 0.289380 0.444991 0.163370\n",
      " 0.082325 0.184145 0.550146 0.115828 0.008301 0.141579 0.193071 0.128147\n",
      " 0.056816 0.408135 0.213831 0.164747 0.271480 0.219975 0.227132 0.116667\n",
      " 0.170695 0.097732 0.193326 0.297322 0.240925 0.204368 0.076399 0.025505\n",
      " 0.397828 0.295900 0.232097 0.206203 0.026091 0.237565 0.298044 0.098219\n",
      " 0.185154 0.083181 0.392678 0.240769 0.392924 0.090288 0.311557 0.079063\n",
      " 0.126168 0.106657 0.096738 0.356238 0.324030 0.116337 0.184156 0.268226\n",
      " 0.030368 0.122968 0.394283 0.506945 0.038054 0.101757 0.114022 0.239222\n",
      " 0.075823 0.464715 0.061802 0.241150 0.156510 0.268392 0.088919 0.131564\n",
      " 0.277810 0.233316 0.377841 0.216636 0.191506 0.064988 0.149028 0.467008\n",
      " 0.035160 0.104154 0.047115 0.346563]\n",
      "Final policy [0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 1.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 1.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000 0.000000 1.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 1.000000 0.000000 0.000000 1.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000]\n"
     ]
    }
   ],
   "source": [
    "curr_policy = np.random.uniform(0,1,size=(n*m))\n",
    "new_policy = init_policy\n",
    "print('Starting policy',init_policy)\n",
    "\n",
    "while np.count_nonzero(curr_policy - new_policy) > 0:\n",
    "    curr_policy = new_policy\n",
    "    Pi = get_Pi(curr_policy,n,m)\n",
    "    mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "    q_vals_utility = np.dot(np.linalg.inv(mat),utility)\n",
    "    new_policy = policy_iter(q_vals_utility,n,m)\n",
    "    \n",
    "print('Final policy',new_policy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.556458336351498\n"
     ]
    }
   ],
   "source": [
    "ell_utility_star = ell(q_vals_utility,new_policy,rho)\n",
    "print(ell_utility_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the optimal reward value from LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal reward value: 8.163862517858446\n",
      "Optimal policy: [0.000000 1.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 0.000000\n",
      " 0.999999 0.000001 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000\n",
      " 0.000000 1.000000 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000001\n",
      " 0.000000 0.999999 0.000000 1.000000 0.000000 0.000000 0.000000 0.000000\n",
      " 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.350830 0.000000\n",
      " 0.649170 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000\n",
      " 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000 1.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 0.000000 0.000000 1.000000 0.000000 0.000000\n",
      " 0.000000 0.000000 0.000000 1.000000]\n"
     ]
    }
   ],
   "source": [
    "## linear programming solver\n",
    "\n",
    "# minimize c @ x\n",
    "# \n",
    "# such that \n",
    "#          A_ub @ x <= b_ub\n",
    "#          A_eq @ x == b_eq\n",
    "#          lb <= x <= ub\n",
    "\n",
    "c = -reward\n",
    "A_ub = -utility.reshape(1, n*m)\n",
    "b_ub = np.zeros(1)\n",
    "\n",
    "prob_transition_lp = np.transpose(prob_transition)\n",
    "\n",
    "E_sum = np.full_like(prob_transition_lp, 0)\n",
    "for i in range(n):\n",
    "    E_sum[i,m*i:m*(i+1)] = np.ones(m)\n",
    "    \n",
    "A_eq = E_sum - gamma*prob_transition_lp\n",
    "b_eq = rho\n",
    "\n",
    "lb = np.zeros(n*m)\n",
    "ub = np.ones(n*m)\n",
    "ub = ub/(1-gamma)\n",
    "bounds = np.transpose([lb, ub])\n",
    "\n",
    "eps = 0.001\n",
    "\n",
    "res = linprog(c, A_ub, b_ub, A_eq, b_eq, bounds)\n",
    "\n",
    "print('Optimal reward value:',-res.fun)\n",
    "\n",
    "print('Optimal policy:',theta_to_policy_naive(res.x,n,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized NPG primal dual method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Policy search via regularized NPG primal dual method \n",
    "Input: n, m, prob_transition, gamma, reward, utility, stepsize, tau, total_iterates   \n",
    "Output: function values of reward and utility  \n",
    "'''\n",
    "\n",
    "def Reg_NPG_primal_dual(n, m, prob_transition, gamma, reward, utility, stepsize, tau, total_iterates):\n",
    "\n",
    "    theta = np.random.uniform(0,1,size=n*m)\n",
    "    dual = 0\n",
    "    conserv = 0.1\n",
    "    reward_value = []\n",
    "    utility_value = []\n",
    "\n",
    "    for k in range(total_iterates):\n",
    "        prob = theta_to_policy_cutoff(theta,n,m)\n",
    "\n",
    "        Pi = get_Pi(prob,n,m)\n",
    "        mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "        qvals_reward = np.dot(np.linalg.inv(mat),reward)\n",
    "        qvals_utility = np.dot(np.linalg.inv(mat),utility)\n",
    "\n",
    "        P_theta = np.matmul(Pi,prob_transition)\n",
    "        d_pi = (1-gamma)*np.dot(np.transpose((np.linalg.inv(np.identity(n) - gamma*P_theta))),rho)\n",
    "    \n",
    "        # entropy \n",
    "        qvals_entropy = np.dot(np.linalg.inv(mat),-np.log(prob))\n",
    "    \n",
    "        # natural gradient \n",
    "        qvals = qvals_reward + dual*qvals_utility + tau*qvals_entropy\n",
    "    \n",
    "        # natural gradient ascent\n",
    "        theta += stepsize*avals(qvals,prob)\n",
    "    \n",
    "        # dual desceent \n",
    "        violation_gradient = ell(qvals_utility,prob,rho) - conserv\n",
    "        dual = (1-stepsize*tau)*dual - stepsize*violation_gradient\n",
    "        dual = proj(dual,gamma)\n",
    "    \n",
    "    \n",
    "        if k % 1 == 0:\n",
    "        \n",
    "        # record iterates\n",
    "        \n",
    "            # record values\n",
    "            avg_reward = ell(qvals_reward,prob,rho)\n",
    "            avg_utility = ell(qvals_utility,prob,rho)\n",
    "            reward_value.append(avg_reward)\n",
    "            utility_value.append(avg_utility)\n",
    "            \n",
    "    return reward_value, utility_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimistic NPG primal dual method (OGDA version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Policy search via optimistic NPG primal dual method\n",
    "Input: n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates   \n",
    "Output: function values of reward and utility  \n",
    "'''\n",
    "\n",
    "def Opt_NPG_primal_dual(n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates):\n",
    "\n",
    "    conserv = 0.1\n",
    "    theta = np.random.uniform(0,1,size=n*m)\n",
    "    theta_h = np.random.uniform(0,1,size=n*m)\n",
    "    dual = 0\n",
    "    dual_h = 0\n",
    "    reward_value = []\n",
    "    utility_value = []\n",
    "    for k in range(total_iterates):\n",
    "    \n",
    "        # optimistic step for (theta, dual)  \n",
    "        Pi = get_Pi(theta,n,m)\n",
    "        mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "        qvals_reward = np.dot(np.linalg.inv(mat),reward)\n",
    "        qvals_utility = np.dot(np.linalg.inv(mat),utility)\n",
    "        violation_gradient = ell(qvals_utility,theta,rho) - conserv\n",
    "    \n",
    "        # gradient \n",
    "        qvals = qvals_reward + dual*qvals_utility\n",
    "\n",
    "        # natural gradient ascent\n",
    "        theta = project_to_policy(theta_h + stepsize*qvals,n,m)\n",
    "    \n",
    "        # dual descent \n",
    "        dual = dual_h - stepsize*violation_gradient\n",
    "        dual = proj(dual,gamma)\n",
    "\n",
    "        # optimistic step for (theta_h, dual_h)    \n",
    "        Pi = get_Pi(theta,n,m)\n",
    "        mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "        qvals_reward = np.dot(np.linalg.inv(mat),reward)\n",
    "        qvals_utility = np.dot(np.linalg.inv(mat),utility)\n",
    "        violation_gradient = ell(qvals_utility,theta,rho) - conserv\n",
    "        \n",
    "        # gradient \n",
    "        qvals = qvals_reward + dual*qvals_utility\n",
    "    \n",
    "        # natural gradient ascent\n",
    "        theta_h = project_to_policy(theta_h + stepsize*qvals,n,m)\n",
    "    \n",
    "        # dual desceent \n",
    "        dual_h = dual_h - stepsize*violation_gradient\n",
    "        dual_h = proj(dual_h,gamma)\n",
    "    \n",
    "        if k % 1 == 0:\n",
    "            avg_reward = ell(qvals_reward,theta_h,rho)\n",
    "            avg_utility = ell(qvals_utility,theta_h,rho)\n",
    "            reward_value.append(avg_reward)\n",
    "            utility_value.append(avg_utility)\n",
    "            \n",
    "    return reward_value, utility_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPG primal method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Policy search via NPG primal dual method \n",
    "Input: n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates   \n",
    "Output: function values of reward and utility  \n",
    "'''\n",
    "def NPG_primal(n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates):\n",
    "\n",
    "    alpha = 1\n",
    "    beta = 0.7\n",
    "    theta = np.random.uniform(0,1,size=n*m)\n",
    "    reward_value = []\n",
    "    utility_value = []\n",
    "\n",
    "    for k in range(total_iterates):\n",
    "        prob = theta_to_policy(theta,n,m)\n",
    "\n",
    "        Pi = get_Pi(prob,n,m)\n",
    "        mat = np.identity(n*m) - gamma*np.matmul(prob_transition,Pi)\n",
    "        qvals_reward = np.dot(np.linalg.inv(mat),reward)\n",
    "        qvals_utility = np.dot(np.linalg.inv(mat),utility)\n",
    "\n",
    "        P_theta = np.matmul(Pi,prob_transition)\n",
    "        d_pi = (1-gamma)*np.dot(np.transpose((np.linalg.inv(np.identity(n) - gamma*P_theta))),rho)\n",
    "    \n",
    "        # primal method that uses NPG as policy update \n",
    "        if ell(qvals_utility,prob,rho) >= -1/np.sqrt(k+1):\n",
    "            gradient = grad(qvals_reward,prob,d_pi)\n",
    "        else:\n",
    "            gradient = grad(qvals_utility,prob,d_pi)\n",
    "    \n",
    "        # natural gradient\n",
    "        Fisher_inv = np.linalg.pinv(Fisher_info(prob,d_pi))\n",
    "        natural_gradient = np.matmul(Fisher_inv,gradient)\n",
    "            \n",
    "        # natural gradient ascent\n",
    "        theta += stepsize*natural_gradient\n",
    "\n",
    "\n",
    "        if k % 1 == 0:\n",
    "        \n",
    "        # record iterates\n",
    "        \n",
    "            # record values\n",
    "            avg_reward = ell(qvals_reward,prob,rho)\n",
    "            avg_utility = ell(qvals_utility,prob,rho)\n",
    "            reward_value.append(avg_reward)\n",
    "            utility_value.append(avg_utility)\n",
    "        \n",
    "    return reward_value, utility_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_iterates = 1060\n",
    "stepsize = 0.1\n",
    "\n",
    "# call regularized NPG primal dual method\n",
    "\n",
    "tau = 0.08\n",
    "\n",
    "reward_value_reg, utility_value_reg = Reg_NPG_primal_dual(n, m, prob_transition, gamma, reward, utility, stepsize, tau, total_iterates)\n",
    "\n",
    "# call optimistic NPG primal dual method\n",
    "\n",
    "reward_value_opt, utility_value_opt = Opt_NPG_primal_dual(n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates)\n",
    "\n",
    "# call NPG primal method\n",
    "\n",
    "stepsize = 0.1\n",
    "\n",
    "reward_value_primal, utility_value_primal = NPG_primal(n, m, prob_transition, gamma, reward, utility, stepsize, total_iterates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot reward value vs policy iterate \n",
    "\n",
    "f_value = plt.figure\n",
    "\n",
    "num_every = 20\n",
    "num_grads = np.arange(0, total_iterates, num_every)\n",
    "\n",
    "reward_value_primal = np.array(reward_value_primal)\n",
    "reward_value_reg = np.array(reward_value_reg)\n",
    "reward_value_opt = np.array(reward_value_opt)\n",
    "\n",
    "plt.plot(num_grads,reward_value_primal[::num_every], \"k-.\", linewidth=2)\n",
    "plt.plot(num_grads,reward_value_reg[::num_every], \"b--\",linewidth=2)\n",
    "plt.plot(num_grads,reward_value_opt[::num_every], \"r-\",linewidth=2)\n",
    "plt.grid(axis='y', color='0.85')\n",
    "plt.draw()\n",
    "get_f_value = plt.gcf()\n",
    "get_f_value.savefig('NPG_primal_conserv_comparison_reward.png',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot utility value vs policy iterate \n",
    "\n",
    "g_value = plt.figure\n",
    "\n",
    "num_every = 20\n",
    "num_grads = np.arange(0, total_iterates, num_every)\n",
    "\n",
    "utility_value_primal = np.array(utility_value_primal)\n",
    "utility_value_reg = np.array(utility_value_reg)\n",
    "utility_value_opt = np.array(utility_value_opt)\n",
    "\n",
    "plt.plot(num_grads,utility_value_primal[::num_every], \"k-.\", linewidth=2)\n",
    "plt.plot(num_grads,utility_value_reg[::num_every], \"b--\", linewidth=2)\n",
    "plt.plot(num_grads,utility_value_opt[::num_every], \"r-\", linewidth=2)\n",
    "plt.grid(axis='y', color='0.85')\n",
    "plt.draw()\n",
    "get_g_value = plt.gcf()\n",
    "get_g_value.savefig('NPG_primal_conserv_comparison_utility.png',dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
